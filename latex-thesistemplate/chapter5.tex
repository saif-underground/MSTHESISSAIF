% chap5.tex (Methodology and Result)

\chapter{Methodology and Result}

Traditioanlly, a single predictor served to predict the energy demand of all powertype customers. Since each powertype customers acts differently, I have attempted to attack each type of customer separately to make a prediction mechanism that perfroms better than the baseline predictor.

\section{Baseline Predictor}
Baseline predictor is the default prediction mechanism provided by the PowerTAC system. It exploits the fact that usage of a timeslot of a customer in a specific date is highly correlated with the day of the week and the time slot. To make prediction it stores the average energy usage of an hour of a week. So, for each customer it uses $24*7 = 168$ memory to remember average usages. As soon as it learns about a new usage information of an hour of a week, it updates old average using the following algorithm.


\begin{algorithm}
\caption{Calculate average usage for day d and timeslot t, $avgUsage$}
\begin{algorithmic} 
\STATE Initialize
\STATE $avgUsage = 0$
\STATE Update
\STATE $avgUsage = 0.7 * avgUsage + 0.3 * oldUsage$
\STATE Predict usage for day d and time slot t
\STATE return $avgUsage$
\end{algorithmic}
\end{algorithm}

There will be another type of predictor that is designed to make prediction for a single customer. In general, if there are n customers in the system, we will need n predictor each one trained on a single customer. I went further by checking different machine learning algorithms such as M5Tree, Linear Regression, M5P rules and REP tree for each customer and picked the best performing one for each customer.

\section{Prediction Mechanism}

In this section I will describe how I attempted to make predictor for each of the powertypes.

\subsection{Consumption Type Customer}
For the consumption type customers, the following algorithm is used to make prediction about them.
\begin{algorithm}
\caption{Make prediction for consumption type customer}
\begin{algorithmic} 
\STATE Cluster the consumption customers based on their average weekly usage.
\STATE For each cluster, find the best performing predictor.
\STATE To predict about a new customer, see which cluster it falls into.
\STATE Use that cluster's predictor to predict about the customer.
\end{algorithmic}
\end{algorithm}

To make the cluster, the extractor program extracts consumption customer's information from 30 game logs. In the first phase, it collects the weekly usages. So from each log file and for each customer, the program extracts 24 * 7 values, each of the value represent average usage of an hour in a weekday. In the second phase, the clustering algorithm clusters based on the extracted weekly average usages. Once the cluster is made, the second extractor programs extracts slot based information of all the customers in a given slot and makes a training set out of it. In the next phase, a program creates creates several machine learning predictors such as linear regression, decision trees etc and figures out which performs best for the cluster. The best performing predictor is used to make prediction about the cluster. In the runtime, a customer will be grouped in a cluster based on its weekly usage. Once the program knows the cluster assigned for a customer, the program loads the corresponding predictor to predict about the new customer. 


\section{Result}
\subsection{Finding number of clusters}

At first, I have segmented the customer using KMeans clustering algorithm with cluster sizes = 4, 5, 6, 7, 8, 9, 10 and 11. For KMeans with size k, we will have k clusters. For each of the k clusters I had a linear regression predictor. I observed the relative percentage error and absolute average the above cluster sizes. Figure \ref{fig:cluster-type-vs-error} shows the result. From, the figure it is clear that the size of the cluster does not have a big impact on the prediction performance.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{cluster-types-vs-error.png}
  \caption{Cluster type vs Error.}
  \label{fig:cluster-type-vs-error}
\end{figure}

To keep things simple, I have decided to choose Kmeans cluster of size 4. The figure \ref{fig:4-cluster-with-10-files} shows the assignments of customers in different clusters. From the figure, cluster-0 holds most of the offices, cluster 2 holds most of the village types, cluster 3 holds the medical center, cluster 1 holds large housing such as brooksidehomes, centerville homes etc.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{4-cluster-with-10-files.png}
  \caption{Cluster assignments.}
  \label{fig:4-cluster-with-10-files}
\end{figure}

\subsection {Finding best predictor for each cluster}
Next, I have tried out  M5Tree, Linear Regression, M5P rules and REP tree machine learning algorithms to see which one performs best for each of the 4 clusters. Figure \ref{fig:cluster-0-predictors}, \ref{fig:cluster-1-predictors}, \ref{fig:cluster-2-predictors}, \ref{fig:cluster-3-predictors} show that M5P, M5P, REPTree and M5RULES are the best predictors for cluster 0, 1, 2 and 3 respectively.


\begin{figure}[h!]
  \includegraphics[width=\linewidth]{cluster-0-predictors.png}
  \caption{Performance of differenc predictors for cluster 0}
  \label{fig:cluster-0-predictors}
\end{figure}

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{cluster-1-predictors.png}
  \caption{Performance of differenc predictors for cluster 1}
  \label{fig:cluster-1-predictors}
\end{figure}


\begin{figure}[h!]
  \includegraphics[width=\linewidth]{cluster-2-predictors.png}
  \caption{Performance of differenc predictors for cluster 2}
  \label{fig:cluster-2-predictors}
\end{figure}


\begin{figure}[h!]
  \includegraphics[width=\linewidth]{cluster-3-predictors.png}
  \caption{Performance of differenc predictors for cluster 3}
  \label{fig:cluster-3-predictors}
\end{figure}

The next step is to find the best predictors for each of the customers. Based on the data from each of the customers, the above four types of predictors were tried out. For each customer, the following predictors performed the best. 

\begin{table}[h!]
\centering
\begin{tabular}{|c| c|} 
 \hline
 Customer Name & Best Predictor Type \\ [0.5ex] 
 \hline
BrooksideHomes &	M5P \\
CentervilleHomes &	M5P \\
DowntownOffices &	M5P \\
EastsideOffices &	M5P \\
OfficeComplex 1 NS Base &	LinearRegression \\
OfficeComplex 1 SS Base &	LinearRegression \\
OfficeComplex 2 NS Base &	LinearRegression \\
OfficeComplex 2 SS Base &	LinearRegression \\
Village 1 NS Base &	M5P \\
Village 1 RaS Base &	LinearRegression \\
Village 1 ReS Base &	M5P \\
Village 1 SS Base &	M5P \\
Village 2 NS Base &	LinearRegression \\
Village 2 RaS Base &	M5P \\
Village 2 ReS Base &	M5P \\
Village 2 SS Base &	M5P \\
MedicalCenter@1	& M5P \\ [1ex] 
 \hline
\end{tabular}
\caption{Best individual predictor for each customer}
\label{table:1}
\end{table}

The figure \ref{fig:indiv-cutomer-best-predictor-error} shows error percentage of each of the predictors type for each of the customer types.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{indiv-cutomer-best-predictor-error.png}
  \caption{Performance of the best predictors for each customer type. Customer Medical center was excluded as it was showing huge error. }
  \label{fig:indiv-cutomer-best-predictor-error}
\end{figure}

Finally, the cluster based prediction and the two baselines were tested with data extracted from 5 test files that were not used for training. From Figure \ref{fig:prediction-scheme-vs-error} we can see that cluster based prediction mechanism performed almost as well as the mechanism where n predictors are needed for n customers. And it did well than the moving average prediction scheme.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{prediction-scheme-vs-error.png}
  \caption{Performance of the three prediction mechanisms. Cluster based predictor performs as good as the individual predictor for each customers and performs better than the moving average predictor. }
  \label{fig:prediction-scheme-vs-error}
\end{figure}